## Python爬虫前，抓包

### 00

- 什么是爬虫：网页网站都是有许多的数据构成的，我们需要做一个自动化程序获取这些数据并把这些数据进行整理、分析后，输出为有用直观的信息，这个过程就是爬虫。

- 爬虫的具体流程：

1.模拟浏览器请求

2.服务器返回数据到爬虫程序（数据的类型：HTML、JSON、二进制的数据等）

3.数据的保存（数据库、硬盘等）

### 01

- HTTP的请求方式

1.GET

2.POST

- Response Headers：服务器的响应

- Request Headers：向浏览器发出访问请求时提交的信息

不同的请求获得的数据是不一样的

### 02

通过Fiddler进行手机抓包

## Python爬虫需要用到的库的学习

urllib库：（模拟浏览器）对url进行访问请求并返回一个响应，这个响应就是该url的源码

```python
import urllib.request
#伪装浏览器对扇贝进行访问请求并返回响应

url1 = 'https://www.shanbay.com/'
headers1 = {'user-agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'}
req1 = urllib.request.Request(url=url1,headers=headers1)
response = urllib.request.urlopen(req1)
print(response.read().decode('utf-8'))
```

正则表达式过滤得到的响应，筛选出我们需要的信息

正则表达式的原理是通过定义一些特殊的符号来匹配不同的字符