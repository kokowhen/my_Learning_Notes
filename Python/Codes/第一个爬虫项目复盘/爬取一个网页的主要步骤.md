# 主要用到的库：

- import urllib.request

- import re

- from bs4 import BeautifulSoup

# 主要步骤

## 爬取网页的源码

- 1.把网页链接存放到一个变量里：url = 需要爬取的网址

- 2.浏览器访问请求伪装：headers = {  " " ：" " }

- 3.发出网页访问请求：req = urllib.request.Request(url=url,headers=headers)

- 4.接收访问到的网页源码并解码成"utf-8"格式：response = urllib.request(req).read().decode("utf-8")

- 通过print(response)我们可以知道，它和网页源码是一样的，如果复制打印得到的代码并保存成html文件，打开该文件的效果和网页的效果一样

## 通过html源码制定需要爬取内容的正则表达式规则

- 1.假设标题的正则表达式为：titlerule = re.compile(r' ')

- 2.假设名字的正则表达式为：namerule = re.compile(r' ')

## 解析源码，提取指定的字符串

- 1.先通过bs库的htm对象解析得到树形结构数据（构建BeautifulSoup实例）：

  > bs = BeautifulSoup(response,"html.parser")

- 2.筛选出所有匹配到的结果并返回到一个列表中，列表中的元素是符合要求的html代码

  > titlelist = bs.find_all("标签","属性")

  > Note：（bs.find( )只返回第一个找到的对象；bs.find_all返回所有匹配到的结果）

## 提取列表里满足正则表达式要求的字符串

- 1.先将列表中的元素遍历出来

  > for item in titlelist:

- 将item转化为字符串

  > item = str(item)

- 3.对每一个元素进行正则规则判断，并返回符合规则的字符串

  > title = re.findall(titlerule,item)

- 4.输出title



